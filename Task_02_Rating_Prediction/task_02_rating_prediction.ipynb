{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project task 02: Restaurant recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this task is to recommend restaurants to users based on the rating data in the Yelp dataset. For this, we try to predict the rating a user will give to a restaurant they have not been to yet based on a latent factor model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download `ratings.npy` from Piazza ([download link](https://syncandshare.lrz.de/dl/fiKMoxRNusLoFpFHkXXEgvdZ/ratings.npy))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.load(\"ratings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have triplets of (user, restaurant, rating).\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform the data into a matrix of dimension [N, D], where N is the number of users and D is the number of restaurants in the dataset.  \n",
    "We **strongly recommend** to load the data as a sparse matrix to avoid out-of-memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the matrix into the variable M\n",
    "\n",
    "### YOUR CODE HERE ### ===> DONE\n",
    "M = sp.csr_matrix((ratings[:,2], (ratings[:,0], ratings[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preprocessing step, we recursively remove all users and restaurants with 10 or less ratings. \n",
    "\n",
    "Then, we randomly select 200 data points for the validation and test sets, respectively.\n",
    "\n",
    "After this, we subtract the mean rating for each users to account for this global effect.   \n",
    "**Hint**: Some entries might become zero in this process -- but these entries are different than the 'unknown' zeros in the matrix. Store the indices of which we have data available in a separate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cold_start_preprocessing(matrix, min_entries):\n",
    "    \"\"\"\n",
    "    Recursively removes rows and columns from the input matrix which have less than min_entries nonzero entries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix      : sp.spmatrix, shape [N, D]\n",
    "                  The input matrix to be preprocessed.\n",
    "    min_entries : int\n",
    "                  Minimum number of nonzero elements per row and column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matrix      : sp.spmatrix, shape [N', D']\n",
    "                  The pre-processed matrix, where N' <= N and D' <= D\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"Shape before: {}\".format(matrix.shape))\n",
    "    \n",
    "    ### YOUR CODE HERE ### ===> DONE\n",
    "    \n",
    "    #Preprocessing is done by applying the recursive function preproc_matrix from the task_02_func.py file\n",
    "    from task_02_func import preproc_matrix   \n",
    "    \n",
    "    matrix = preproc_matrix(matrix, min_entries)[0]\n",
    "\n",
    "    nnz = matrix>0\n",
    "    assert (nnz.sum(0).A1 > min_entries).all()\n",
    "    assert (nnz.sum(1).A1 > min_entries).all()\n",
    "    \n",
    "    print(\"Shape after: {}\".format(matrix.shape))\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_user_mean(matrix):\n",
    "    \"\"\"\n",
    "    Subtract the mean rating per user from the non-zero elements in the input matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : sp.spmatrix, shape [N, D]\n",
    "             Input sparse matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    matrix : sp.spmatrix, shape [N, D]\n",
    "             The modified input matrix.\n",
    "    \n",
    "    user_means : np.array, shape [N, 1]\n",
    "                 The mean rating per user that can be used to recover the absolute ratings from the mean-shifted ones.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE ### ===> DONE\n",
    "    \n",
    "    #Compute the mean for each row (user) considering only nonzero elements\n",
    "    user_means = np.array([matrix.sum(axis = 1).A1 / matrix.getnnz(axis = 1)]).T\n",
    "    \n",
    "    #Create a matrix where each nonzero entry from the original matrix \n",
    "    #is replaced by its row's mean\n",
    "    matrix_means = sp.diags(np.ravel(user_means)).dot(matrix.sign())\n",
    "    \n",
    "    #Substracting this matrix from the original one makes sure \n",
    "    #that only nonzero entries are shifted\n",
    "    matrix = matrix - matrix_means\n",
    "    \n",
    "    assert np.all(np.isclose(matrix.mean(1), 0))\n",
    "    return matrix, user_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(matrix, n_validation, n_test):\n",
    "    \"\"\"\n",
    "    Extract validation and test entries from the input matrix. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix          : sp.spmatrix, shape [N, D]\n",
    "                      The input data matrix.\n",
    "    n_validation    : int\n",
    "                      The number of validation entries to extract.\n",
    "    n_test          : int\n",
    "                      The number of test entries to extract.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matrix_split    : sp.spmatrix, shape [N, D]\n",
    "                      A copy of the input matrix in which the validation and test entries have been set to zero.\n",
    "    \n",
    "    val_idx         : tuple, shape [2, n_validation]\n",
    "                      The indices of the validation entries.\n",
    "    \n",
    "    test_idx        : tuple, shape [2, n_test]\n",
    "                      The indices of the test entries.\n",
    "    \n",
    "    val_values      : np.array, shape [n_validation, ]\n",
    "                      The values of the input matrix at the validation indices.\n",
    "                      \n",
    "    test_values     : np.array, shape [n_test, ]\n",
    "                      The values of the input matrix at the test indices.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE ### ==> DONE\n",
    "    \n",
    "    #Get the indices of all nonzero elements in the matrix\n",
    "    (row_nonzero, col_nonzero) = M.nonzero()\n",
    "    #Sample the indices for validation and test data together from all nonzero elements\n",
    "    #(by this avoid accidentally picking data point for validation and test at the same time)\n",
    "    rand_idx = np.random.choice(len(row_nonzero), n_validation + n_test, replace = False)\n",
    "    #Split validation and test indices\n",
    "    rand_idx_val = rand_idx[:n_validation]\n",
    "    val_idx = (row_nonzero[rand_idx_val], col_nonzero[rand_idx_val])\n",
    "    rand_idx_test = rand_idx[n_validation:]\n",
    "    test_idx = (row_nonzero[rand_idx_test], col_nonzero[rand_idx_test])\n",
    "    \n",
    "    #Get the values of the validation and the test data  \n",
    "    val_values = np.ravel(matrix[val_idx])\n",
    "    test_values = np.ravel(matrix[test_idx])\n",
    "    #Make a copy of the input matrix in which the validation and test entries are set to zero\n",
    "    matrix_split = matrix\n",
    "    matrix_split[val_idx] = 0\n",
    "    matrix_split[test_idx] = 0\n",
    "    \n",
    "    matrix_split.eliminate_zeros()\n",
    "    return matrix_split, val_idx, test_idx, val_values, test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cold_start_preprocessing(M, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_validation = 200\n",
    "n_test = 200\n",
    "# Split data\n",
    "M_train, val_idx, test_idx, val_values, test_values = split_data(M, n_validation, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store away the nonzero indices of M before subtracting the row means.\n",
    "nonzero_indices =  M_train.nonzero() ### YOUR CODE HERE ### ==> DONE\n",
    "# Remove user means.\n",
    "M_shifted, user_means = shift_user_mean(M_train)\n",
    "\n",
    "# Apply the same shift to the validation and test data.\n",
    "val_values_shifted = np.ravel(np.array([val_values[idx] - user_means[val_idx[0][idx]] \\\n",
    "                               for idx in range(len(val_values))])) ### YOUR CODE HERE ### ==> DONE\n",
    "test_values_shifted = np.ravel(np.array([test_values[idx] - user_means[test_idx[0][idx]] \\\n",
    "                                for idx in range(len(test_values))])) ### YOUR CODE HERE ### ==> DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Alternating optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, we will approach the problem via alternating optimization, as learned in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_Q_P(matrix, k, init='random'):\n",
    "    \"\"\"\n",
    "    Initialize the matrices Q and P for a latent factor model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : sp.spmatrix, shape [N, D]\n",
    "             The matrix to be factorized.\n",
    "    k      : int\n",
    "             The number of latent dimensions.\n",
    "    init   : str in ['svd', 'random'], default: 'random'\n",
    "             The initialization strategy. 'svd' means that we use SVD to initialize P and Q, 'random' means we initialize\n",
    "             the entries in P and Q randomly in the interval [0, 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Q : np.array, shape [N, k]\n",
    "        The initialized matrix Q of a latent factor model.\n",
    "\n",
    "    P : np.array, shape [k, D]\n",
    "        The initialized matrix P of a latent factor model.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if init == 'svd':\n",
    "        ### YOUR CODE HERE ### ==> DONE\n",
    "        u, s, vt = svds(matrix, k)\n",
    "        #in our problem we havethe form Q = UE, so we multiply s into u\n",
    "        Q = u.dot(np.diag(s))\n",
    "        P = vt\n",
    "    elif init == 'random':\n",
    "        ### YOUR CODE HERE ### ==> DONE\n",
    "        Q = np.random.rand(matrix.shape[0], k)\n",
    "        P = np.random.rand(k, matrix.shape[1])\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "    assert Q.shape == (matrix.shape[0], k)\n",
    "    assert P.shape == (k, matrix.shape[1])\n",
    "    return Q, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_update(matrix_M, matrix_fixed, matrix_to_be_updated, nonzero_n, nonzero_m, reg_strength):\n",
    "    #assumption        matrix_M = matrix_fixed * matrix_to_be_updated\n",
    "    #dimensions:        n x m         n x d             d x m\n",
    "    #in case of P update: n = numbers of users,       m = numbers of restaurants\n",
    "    #in case of P update: n = numbers of restaurants, m = numbers of users\n",
    "    #Matrix with collected optimal updates\n",
    "    \n",
    "    matrix_optimal = np.zeros((matrix_to_be_updated.shape[0], matrix_to_be_updated.shape[1]))\n",
    "\n",
    "    #ridge regression with closed form solution\n",
    "    model = Ridge(alpha=reg_strength)\n",
    "    matrix_M_T = sp.csr_matrix(matrix_M.transpose())\n",
    "\n",
    "    for counter in range(matrix_to_be_updated.shape[1]):\n",
    "        #find users that correspond to the item        \n",
    "        relevant_indices = nonzero_n[nonzero_m == counter]        \n",
    "        #solution with solver\n",
    "        abg = matrix_M_T[nonzero_m[nonzero_m == counter], relevant_indices].A1\n",
    "        model.fit(matrix_fixed[relevant_indices,:], abg)\n",
    "        matrix_optimal[:,counter] = model.coef_.T\n",
    "        \n",
    "    return matrix_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calculation(values, indices, Q, P):\n",
    "\n",
    "    #build matrix with guessed ratings from Q and P\n",
    "    M_guess = Q.dot(P)\n",
    "    #compute difference between real values and guessed values\n",
    "    diff = values - M_guess[indices]\n",
    "    #compute loss as L2**2 norm\n",
    "    loss = np.linalg.norm(diff) ** 2\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_factor_alternating_optimization(M, non_zero_idx, k, val_idx, val_values,\n",
    "                                           reg_lambda, max_steps=100, init='random',\n",
    "                                           log_every=1, patience=10, eval_every=1):\n",
    "    \"\"\"\n",
    "    Perform matrix factorization using alternating optimization. Training is done via patience,\n",
    "    i.e. we stop training after we observe no improvement on the validation loss for a certain\n",
    "    amount of training steps. We then return the best values for Q and P oberved during training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M                 : sp.spmatrix, shape [N, D]\n",
    "                        The input matrix to be factorized.\n",
    "                      \n",
    "    non_zero_idx      : np.array, shape [nnz, 2]\n",
    "                        The indices of the non-zero entries of the un-shifted matrix to be factorized. \n",
    "                        nnz refers to the number of non-zero entries. Note that this may be different\n",
    "                        from the number of non-zero entries in the input matrix M, e.g. in the case\n",
    "                        that all ratings by a user have the same value.\n",
    "    \n",
    "    k                 : int\n",
    "                        The latent factor dimension.\n",
    "    \n",
    "    val_idx           : tuple, shape [2, n_validation]\n",
    "                        Tuple of the validation set indices.\n",
    "                        n_validation refers to the size of the validation set.\n",
    "                      \n",
    "    val_values        : np.array, shape [n_validation, ]\n",
    "                        The values in the validation set.\n",
    "                      \n",
    "    reg_lambda        : float\n",
    "                        The regularization strength.\n",
    "                      \n",
    "    max_steps         : int, optional, default: 100\n",
    "                        Maximum number of training steps. Note that we will stop early if we observe\n",
    "                        no improvement on the validation error for a specified number of steps\n",
    "                        (see \"patience\" for details).\n",
    "                      \n",
    "    init              : str in ['random', 'svd'], default 'random'\n",
    "                        The initialization strategy for P and Q. See function initialize_Q_P for details.\n",
    "    \n",
    "    log_every         : int, optional, default: 1\n",
    "                        Log the training status every X iterations.\n",
    "                    \n",
    "    patience          : int, optional, default: 10\n",
    "                        Stop training after we observe no improvement of the validation loss for X evaluation\n",
    "                        iterations (see eval_every for details). After we stop training, we restore the best \n",
    "                        observed values for Q and P (based on the validation loss) and return them.\n",
    "                      \n",
    "    eval_every        : int, optional, default: 1\n",
    "                        Evaluate the training and validation loss every X steps. If we observe no improvement\n",
    "                        of the validation error, we decrease our patience by 1, else we reset it to *patience*.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_Q            : np.array, shape [N, k]\n",
    "                        Best value for Q (based on validation loss) observed during training\n",
    "                      \n",
    "    best_P            : np.array, shape [k, D]\n",
    "                        Best value for P (based on validation loss) observed during training\n",
    "                      \n",
    "    validation_losses : list of floats\n",
    "                        Validation loss for every evaluation iteration, can be used for plotting the validation\n",
    "                        loss over time.\n",
    "                        \n",
    "    train_losses      : list of floats\n",
    "                        Training loss for every evaluation iteration, can be used for plotting the training\n",
    "                        loss over time.                     \n",
    "    \n",
    "    converged_after   : int\n",
    "                        it - patience*eval_every, where it is the iteration in which patience hits 0,\n",
    "                        or -1 if we hit max_steps before converging. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE ### ===> DONE\n",
    "    \n",
    "    #Initialization of Q and P\n",
    "    Q, P = initialize_Q_P(M, k, init)\n",
    "    \n",
    "    #init lists\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    list_Qs = []\n",
    "    list_Ps = []\n",
    "    \n",
    "    #temporary patience that is decreased when validation loss stays from iteration to iteration\n",
    "    new_patience = patience\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #initial training data loss\n",
    "    init_train_loss = loss_calculation(M[non_zero_idx], non_zero_idx, Q, P)\n",
    "    init_validation_loss = loss_calculation(val_values, val_idx, Q, P)\n",
    "    print(\"Initial training loss: {0:.3f}, initial validation loss: {1:.3f}\"\\\n",
    "          .format(init_train_loss, init_validation_loss))\n",
    "    \n",
    "    #iterate until max_steps reached\n",
    "    for step in range(max_steps):\n",
    "        \n",
    "        #alternating update of P and Q matrix\n",
    "        P = get_matrix_update(M, Q, P, non_zero_idx[0], non_zero_idx[1], reg_lambda)\n",
    "        Q = get_matrix_update(sp.csr_matrix(M.transpose()), P.T, Q.T, non_zero_idx[1], non_zero_idx[0], reg_lambda).T\n",
    "               \n",
    "        #evaluate losses every eval_every steps\n",
    "        if step % eval_every == 0:\n",
    "            \n",
    "            #add P and Q matrix to list for later choosing of best matrices\n",
    "            list_Qs.append(Q)\n",
    "            list_Ps.append(P)\n",
    "            \n",
    "            #calculate training loss\n",
    "            train_loss = loss_calculation(M[non_zero_idx], non_zero_idx, Q, P)\n",
    "            #add loss to list for e.g. plotting\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            #calculate validation loss\n",
    "            validation_loss = loss_calculation(val_values, val_idx, Q, P)\n",
    "            #add loss to list for choosing of iteration with best loss and e.g. plotting\n",
    "            validation_losses.append(validation_loss)\n",
    "            \n",
    "            #print losses every log_every iterations\n",
    "            if step % log_every == 0:\n",
    "            \n",
    "                print(\"Iteration {0}, training loss: {1:.3f}, validation loss: {2:.3f}\"\\\n",
    "                      .format(step + 1, train_loss, validation_loss))\n",
    "                \n",
    "            try:\n",
    "                #check if validation loss improves\n",
    "                #if not, decrease temporary patience by 1\n",
    "                if (validation_loss >= best_val_loss) or np.isclose(validation_loss, best_val_loss):\n",
    "                    \n",
    "                    new_patience -= 1\n",
    "                    \n",
    "                    #if temporary patience reaches 0 --> stop optimization\n",
    "                    #and return parameters\n",
    "                    if new_patience <= 0:\n",
    "                        \n",
    "                        end_time = time.time()\n",
    "                        \n",
    "                        converged_after = step - patience*eval_every + 1\n",
    "                        \n",
    "                        print(\"Converged after {0} iterations, on average {1:.3f} per iteration\"\\\n",
    "                              .format(converged_after,(end_time - start_time)/step))\n",
    "                        return best_Q, best_P, validation_losses, train_losses, converged_after\n",
    "                \n",
    "                else:\n",
    "                    #if it improves, reset patience to original value\n",
    "                    new_patience = patience\n",
    "                \n",
    "                    #save validation loss for comparison in next steps\n",
    "                    best_val_loss = validation_loss\n",
    "                    #save best Q and P\n",
    "                    best_Q = Q\n",
    "                    best_P = P\n",
    "            \n",
    "            #if previous validation loss does not exist (first iteration)\n",
    "            except NameError:\n",
    "                #save validation loss for comparison in next step\n",
    "                best_val_loss = validation_loss\n",
    "                #save Q and P as initial best\n",
    "                best_Q = Q\n",
    "                best_P = P\n",
    "    \n",
    "    \n",
    "    #after maximum number of steps is reached return parameters\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    converged_after = -1\n",
    "    \n",
    "    print(\"Ran into maximum of {0} steps, on average {1:.3f} per iteration\"\\\n",
    "          .format(max_steps,(end_time - start_time)/max_steps))\n",
    "    \n",
    "    return best_Q, best_P, validation_losses, train_losses, converged_after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the latent factor model with alternating optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Learn the optimal $P$ and $Q$ using alternating optimization. That is, during each iteration you first update $Q$ while having $P$ fixed and then vice versa. Run the alternating optimization algorithm with $k=100$ and $\\lambda=1$. Plot the training and validation losses over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_a, P_a, val_l_a, tr_l_a, conv_a = latent_factor_alternating_optimization(M_shifted, nonzero_indices, \n",
    "                                                                           k=100, val_idx=val_idx,\n",
    "                                                                           val_values=val_values_shifted, \n",
    "                                                                           reg_lambda=1, init='random',\n",
    "                                                                           max_steps=100, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the validation and training losses over (training) time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.plot(range(len(val_l_a)), val_l_a)\n",
    "plt.xticks(np.arange(len(val_l_a), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.title('Alternating optimization validation loss, k = 100')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(tr_l_a)), tr_l_a)\n",
    "plt.xticks(np.arange(len(tr_l_a), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Alternating optimization training loss, k = 100')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) (**Optional**): Try some different latent dimensions $k$ in the range [5, 100]. What do you observe (convergence time, final training/validation losses)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With decreasing number of latent dimensions $k$ our validation loss increases and the convergence time decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_a_2, P_a_2, val_l_a_2, tr_l_a_2, conv_a_2 = latent_factor_alternating_optimization(M_shifted, nonzero_indices, \n",
    "                                                                           k=20, val_idx=val_idx,\n",
    "                                                                           val_values=val_values_shifted, \n",
    "                                                                           reg_lambda=0.1, init='random',\n",
    "                                                                           max_steps=100, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the validation and training losses over (training) time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.plot(range(len(val_l_a_2)), val_l_a_2)\n",
    "plt.xticks(np.arange(len(val_l_a_2), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.title('Alternating optimization validation loss, k = 20')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(tr_l_a_2)), tr_l_a_2)\n",
    "plt.xticks(np.arange(len(tr_l_a_2), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Alternating optimization training loss, k = 20')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Latent factorization using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use gradient descent to factorize our ratings matrix. We will try both (mini-) batch and stochastic gradient descent. You can use the following equations for your implementation.\n",
    "\n",
    "Recall that the objective function (loss) we wanted to optimize was:\n",
    "$$\n",
    "\\mathcal{L} = \\min_{P, Q} \\sum_{(x, i) \\in W} (r_{xi} - \\mathbf{q}_i^T\\mathbf{p}_x)^2 + \\lambda_1\\sum_x{\\left\\lVert \\mathbf{p}_x  \\right\\rVert}^2 + \\lambda_2\\sum_i {\\left\\lVert\\mathbf{q}_i  \\right\\rVert}^2\n",
    "$$\n",
    "\n",
    "where $W$ is the set of $(x, i)$ pairs for which $r_{xi}$ is known (in this case our known play counts). Here we have also introduced two regularization terms to help us with overfitting where $\\lambda_1$ and $\\lambda_2$ are hyper-parameters that control the strength of the regularization.\n",
    "\n",
    "Naturally optimizing with gradient descent involves computing the gradient of the loss function $\\mathcal{L}$ w.r.t. to the parameters. To help you solve the task we provide the following:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial ((r_{xi} - \\mathbf{q}_i^T\\mathbf{p}_x)^2)}{\\partial \\mathbf{p}_x} = -2(r_{xi} - \\mathbf{q}_i^T\\mathbf{p}_x)\\mathbf{q}_i\\;, ~~~\n",
    "\\frac{\\partial ((r_{xi} - \\mathbf{q}_i^T\\mathbf{p}_x)^2)}{\\partial \\mathbf{q}_i} = -2(r_{xi} - \\mathbf{q}_i^T\\mathbf{p}_x)\\mathbf{p}_x \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial(\\lambda_1{\\left\\lVert \\mathbf{p}_x \\right\\rVert}^2)}{\\partial \\mathbf{p}_x} = 2 \\lambda_1 \\mathbf{p_x} \\;, ~~~\n",
    "\\frac{\\partial(\\lambda_2{\\left\\lVert \\mathbf{q}_i \\right\\rVert}^2)}{\\partial \\mathbf{q}_i} = 2 \\lambda_2 \\mathbf{q_i}\n",
    "$$\n",
    "\n",
    "**Hint**: You have to carefully consider how to combine the given partial gradients depending\n",
    "on which variants of gradient descent you are using.  \n",
    "**Hint 2**: It may be useful to scale the updates to $P$ and $Q$ by $\\frac{1}{batch\\_size}$ (in the case of full-sweep updates, this would be $\\frac{1}{n\\_users}$ for $Q$ and $\\frac{1}{n\\_restaurants}$ for $P$).\n",
    "\n",
    "\n",
    "For each of the gradients descent variants you try report and compare the following:\n",
    "* How many iterations do you need for convergence.\n",
    "* Plot the loss (y axis) for each iteration (x axis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(Q, P, M, nonzero_indices, learning_rate, reg_lambda, scale, k):     \n",
    "            \n",
    "        #initialisation of later needed vector or matrices\n",
    "        sum_over_usergradient = np.zeros((M.shape[0], k))\n",
    "        sum_over_itemsgradient = np.zeros((M.shape[1], k))\n",
    "        user_counter = np.zeros(M.shape[0], dtype= int)\n",
    "        items_counter = np.zeros(M.shape[1], dtype= int)\n",
    "        \n",
    "        #get the training data points\n",
    "        r_xi = M[user_indices,items_indices].A1\n",
    "        \n",
    "        #split up tuple into two lists with the indices for the nonzero users and nonzero items\n",
    "        user_indices, items_indices = (nonzero_indices[0], nonzero_indices[1])\n",
    "        \n",
    "        #count how often a specific user/item occurs within the training data for later normalization\n",
    "        np.add.at(user_counter, user_indices, 1)\n",
    "        np.add.at(items_counter, items_indices, 1) \n",
    "        \n",
    "        #compute a piece of the gradient that can be applied to users and items equivalently\n",
    "        gradient_common = -2 * (r_xi - np.sum(Q[user_indices] * P.T[items_indices], axis=1))\n",
    "        \n",
    "        #compute the loss part of the gradient separatly for users and items\n",
    "        gradient_user = gradient_common[:, None] * P.T[items_indices]\n",
    "        gradient_items = gradient_common[:, None] * Q[user_indices]\n",
    "        \n",
    "        #sum up the gradients for each user/item individually\n",
    "        np.add.at(sum_over_usergradient, user_indices, gradient_user)\n",
    "        np.add.at(sum_over_itemsgradient, items_indices, gradient_items)\n",
    "        \n",
    "        #define a mask in order to get the relevant values for the scaling\n",
    "        mask_user = (user_counter != 0)\n",
    "        mask_item = (items_counter != 0)\n",
    "        \n",
    "        #scale the computed gradients individual per user/item\n",
    "        sum_over_usergradient[mask_user] = sum_over_usergradient[mask_user] / user_counter[mask_user, None]\n",
    "        sum_over_itemsgradient[mask_item] = sum_over_itemsgradient[mask_item] / items_counter[mask_item, None]\n",
    "   \n",
    "        #scale the general gradient and add the regularization Parameter\n",
    "        sum_over_usergradient[mask_user] = scale * sum_over_usergradient[mask_user] + 2 * reg_lambda * Q[mask_user]\n",
    "        sum_over_itemsgradient[mask_item] = scale * sum_over_itemsgradient[mask_item] + 2 * reg_lambda * P.T[mask_item]\n",
    "        \n",
    "        #update the matrices P and Q\n",
    "        Q = Q - learning_rate * sum_over_usergradient\n",
    "        P = P - learning_rate * np.transpose(sum_over_itemsgradient)\n",
    "        \n",
    "        return Q ,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_factor_gradient_descent(M, non_zero_idx, k, val_idx, val_values, \n",
    "                                   reg_lambda, learning_rate, batch_size=-1,\n",
    "                                   max_steps=50000, init='random',\n",
    "                                   log_every=1000, patience=20,\n",
    "                                   eval_every=50):\n",
    "    \"\"\"\n",
    "    Perform matrix factorization using gradient descent. Training is done via patience,\n",
    "    i.e. we stop training after we observe no improvement on the validation loss for a certain\n",
    "    amount of training steps. We then return the best values for Q and P oberved during training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M                 : sp.spmatrix, shape [N, D]\n",
    "                        The input matrix to be factorized.\n",
    "                      \n",
    "    non_zero_idx      : np.array, shape [nnz, 2]\n",
    "                        The indices of the non-zero entries of the un-shifted matrix to be factorized. \n",
    "                        nnz refers to the number of non-zero entries. Note that this may be different\n",
    "                        from the number of non-zero entries in the input matrix M, e.g. in the case\n",
    "                        that all ratings by a user have the same value.\n",
    "    \n",
    "    k                 : int\n",
    "                        The latent factor dimension.\n",
    "    \n",
    "    val_idx           : tuple, shape [2, n_validation]\n",
    "                        Tuple of the validation set indices.\n",
    "                        n_validation refers to the size of the validation set.\n",
    "                      \n",
    "    val_values        : np.array, shape [n_validation, ]\n",
    "                        The values in the validation set.\n",
    "                      \n",
    "    reg_lambda        : float\n",
    "                        The regularization strength.\n",
    "\n",
    "    learning_rate     : float\n",
    "                        Step size of the gradient descent updates.\n",
    "                        \n",
    "    batch_size        : int, optional, default: -1\n",
    "                        (Mini-) batch size. -1 means we perform standard full-sweep gradient descent.\n",
    "                        If the batch size is >0, use mini batches of this given size.\n",
    "                        \n",
    "    max_steps         : int, optional, default: 100\n",
    "                        Maximum number of training steps. Note that we will stop early if we observe\n",
    "                        no improvement on the validation error for a specified number of steps\n",
    "                        (see \"patience\" for details).\n",
    "                      \n",
    "    init              : str in ['random', 'svd'], default 'random'\n",
    "                        The initialization strategy for P and Q. See function initialize_Q_P for details.\n",
    "    \n",
    "    log_every         : int, optional, default: 1\n",
    "                        Log the training status every X iterations.\n",
    "                    \n",
    "    patience          : int, optional, default: 10\n",
    "                        Stop training after we observe no improvement of the validation loss for X evaluation\n",
    "                        iterations (see eval_every for details). After we stop training, we restore the best \n",
    "                        observed values for Q and P (based on the validation loss) and return them.\n",
    "                      \n",
    "    eval_every        : int, optional, default: 1\n",
    "                        Evaluate the training and validation loss every X steps. If we observe no improvement\n",
    "                        of the validation error, we decrease our patience by 1, else we reset it to *patience*.\n",
    "                        \n",
    "    Returns\n",
    "    -------\n",
    "    best_Q            : np.array, shape [N, k]\n",
    "                        Best value for Q (based on validation loss) observed during training\n",
    "                      \n",
    "    best_P            : np.array, shape [k, D]\n",
    "                        Best value for P (based on validation loss) observed during training\n",
    "                      \n",
    "    validation_losses : list of floats\n",
    "                        Validation loss for every evaluation iteration, can be used for plotting the validation\n",
    "                        loss over time.\n",
    "                        \n",
    "    train_losses      : list of floats\n",
    "                        Training loss for every evaluation iteration, can be used for plotting the training\n",
    "                        loss over time.                     \n",
    "    \n",
    "    converged_after   : int\n",
    "                        it - patience*eval_every, where it is the iteration in which patience hits 0,\n",
    "                        or -1 if we hit max_steps before converging. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE ### ==> DONE\n",
    "    \n",
    "    #initialization for Q and P\n",
    "    Q,P = initialize_Q_P(M, k, init)\n",
    "    \n",
    "    #init lists\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    list_Qs = []\n",
    "    list_Ps = []\n",
    "    \n",
    "    #temporary patience that is decreased when validation loss stays from iteration to iteration\n",
    "    new_patience = patience\n",
    "        \n",
    "    #initial training data loss\n",
    "    init_train_loss = loss_calculation(M[non_zero_idx], non_zero_idx, Q, P)\n",
    "    init_vali_loss = loss_calculation(val_values, val_idx, Q, P)\n",
    "    print(\"Initial training loss: {0:.3f}, initial validation loss: {1:.3f}\".format(init_train_loss, init_vali_loss))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #iterate until max_steps reached\n",
    "    for step in range(max_steps):\n",
    "        \n",
    "        #full sweep\n",
    "        if batch_size == -1:\n",
    "            \n",
    "            #scale with N/N\n",
    "            scale = 1\n",
    "            \n",
    "            #batch is the whole set of nonzero elements\n",
    "            nonzeros_batch = non_zero_idx\n",
    "            \n",
    "        #mini batch    \n",
    "        else:\n",
    "            #scale with N/b\n",
    "            scale = 1 #len(nonzero_indices[0]) / batch_size\n",
    "            \n",
    "            #choose batch_size random samples from the non_zero_indices\n",
    "            batch_idx = np.random.choice(len(nonzero_indices[0]), size = batch_size, replace = False)\n",
    "            nonzeros_batch = (non_zero_idx[0][batch_idx], non_zero_idx[1][batch_idx])\n",
    "            \n",
    "        #gradient descent update\n",
    "        Q, P = update(Q, P, M, nonzeros_batch, learning_rate, reg_lambda, scale, k)\n",
    "               \n",
    "        #evaluate losses every eval_every steps\n",
    "        if step % eval_every == 0:\n",
    "            \n",
    "            #add P and Q matrix to list for later choosing of best matrices\n",
    "            list_Qs.append(Q)\n",
    "            list_Ps.append(P)\n",
    "            \n",
    "            #calculate training loss\n",
    "            train_loss = loss_calculation(M[non_zero_idx], non_zero_idx, Q, P)\n",
    "            #add loss to list for e.g. plotting\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            #calculate validation loss\n",
    "            validation_loss = loss_calculation(val_values, val_idx, Q, P)\n",
    "            #add loss to list for choosing of iteration with best loss and e.g. plotting\n",
    "            validation_losses.append(validation_loss)\n",
    "            \n",
    "            #print losses every log_every iterations\n",
    "            if step % log_every == 0:\n",
    "            \n",
    "                print(\"Iteration {0}, training loss: {1:.3f}, validation loss: {2:.3f}\".format(step, train_loss, validation_loss))\n",
    "            \n",
    "            try:\n",
    "                #check if validation loss improves\n",
    "                #if not, decrease temporary patience by 1\n",
    "                if (validation_loss >= best_val_loss) or np.isclose(validation_loss, best_val_loss):\n",
    "                    \n",
    "                    new_patience -= 1\n",
    "                    \n",
    "                    #if temporary patience reaches 0 --> stop optimization\n",
    "                    #and return parameters\n",
    "                    if new_patience == 0:\n",
    "                        \n",
    "                        end_time = time.time()\n",
    "                        \n",
    "                        converged_after = step - patience*eval_every\n",
    "                        idx_best_val_l = validation_losses.index(min(validation_losses))\n",
    "                        best_Q = list_Qs[idx_best_val_l]\n",
    "                        best_P = list_Ps[idx_best_val_l]\n",
    "                        \n",
    "                        print(\"Converged after {0} iterations, on average {1:.3f} per iteration\".format(converged_after,(end_time - start_time)/step))\n",
    "                        return best_Q, best_P, validation_losses, train_losses, converged_after\n",
    "                \n",
    "                else:\n",
    "                    #if it improves, reset patience to original value\n",
    "                    new_patience = patience\n",
    "                \n",
    "                    #save validation loss for comparison in next steps\n",
    "                    best_val_loss = validation_loss\n",
    "            \n",
    "            #if previous validation loss does not exist (first iteration)\n",
    "            except NameError:\n",
    "                #save validation loss for comparison in next step\n",
    "                best_val_loss = validation_loss\n",
    "    \n",
    "    \n",
    "    #after maximum number of steps is reached return parameters\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    converged_after = -1\n",
    "    idx_best_val_l = validation_losses.index(min(validation_losses))\n",
    "    best_Q = list_Qs[idx_best_val_l]\n",
    "    best_P = list_Ps[idx_best_val_l]\n",
    "    \n",
    "    print(\"Ran into maximum of {0} steps, on average {1:.3f} per iteration\".format(max_steps,(end_time - start_time)/max_steps))        \n",
    "    \n",
    "            \n",
    "    return best_Q, best_P, validation_losses, train_losses, converged_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the latent factor model with alternating optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Learn the optimal $P$ and $Q$ using standard gradient descent. That is, during each iteration you have to use all of the training examples and update $Q$ and $P$ for all users and songs at once. Try the algorithm with $k=30$, $\\lambda=1$, and learning rate of 0.1. Initialize $Q$ and $P$ with SVD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_g_sweep, P_g_sweep, val_l_g_sweep, tr_l_g_sweep, conv_g_sweep =  latent_factor_gradient_descent(M_shifted, nonzero_indices, \n",
    "                                                                                                   k=30, val_idx=val_idx,\n",
    "                                                                                                   val_values=val_values_shifted, \n",
    "                                                                                                   reg_lambda=1e-0, learning_rate=1e-3,\n",
    "                                                                                                   init='svd', batch_size=-1,\n",
    "                                                                                                   max_steps=10000, log_every=20, \n",
    "                                                                                                   eval_every=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the validation and training losses over (training) time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.plot(range(len(val_l_g_sweep)), val_l_g_sweep)\n",
    "plt.xticks(np.arange(len(val_l_g_sweep), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.title('Gradient descent validation loss, k = 30')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(tr_l_g_sweep)), tr_l_g_sweep)\n",
    "plt.xticks(np.arange(len(tr_l_g_sweep), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Gradient descent training loss, k = 30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Learn the optimal $P$ and $Q$ using the original stochastic gradient descent (mini-batches of size 1). That is, during each iteration you sample a single random training example $r_{xi}$ and update only the respective affected parameters $\\mathbf{p_x}$ and $\\mathbf{q}_i$. Set the learning rate to 0.01 and keep the other parameters as in a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_g_st, P_g_st, val_l_g_st, tr_l_g_st, conv_g_st = latent_factor_gradient_descent(M_shifted, nonzero_indices, \n",
    "                                                                                   k=30, val_idx=val_idx,\n",
    "                                                                                   val_values=val_values_shifted, \n",
    "                                                                                   reg_lambda=1e-1, learning_rate=1e-2,\n",
    "                                                                                   init='svd', batch_size=1,\n",
    "                                                                                   max_steps=20000, log_every=500, \n",
    "                                                                                   eval_every=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the validation and training losses over (training) time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.plot(range(len(val_l_g_st)), val_l_g_st)\n",
    "plt.xticks(np.arange(len(val_l_g_st), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.title('Gradient descent validation loss, k = 30')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(tr_l_g_st)), tr_l_g_st)\n",
    "plt.xticks(np.arange(len(tr_l_g_st), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Gradient descent training loss, k = 30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) (**Optional**) Learn the optimal $P$ and $Q$ similarly to b) this time using larger mini-batches of size $S$, e.g. 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_g_mb, P_g_mb, val_l_g_mb, tr_l_g_mb, conv_g_mb = latent_factor_gradient_descent(M_shifted, nonzero_indices, \n",
    "                                                                                   k=30, val_idx=val_idx,\n",
    "                                                                                   val_values=val_values_shifted, \n",
    "                                                                                   reg_lambda=1, learning_rate=1e-1,\n",
    "                                                                                   init='svd', batch_size=32,\n",
    "                                                                                   max_steps=10000, log_every=100, \n",
    "                                                                                   eval_every=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the validation and training losses over (training) time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.plot(range(len(val_l_g_mb)), val_l_g_mb)\n",
    "plt.xticks(np.arange(len(val_l_g_mb), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.title('Gradient descent validation loss, k = 30')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(tr_l_g_mb)), tr_l_g_mb)\n",
    "plt.xticks(np.arange(len(tr_l_g_mb), step=2))\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Gradient descent training loss, k = 30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models are often heavily dependent on the hyperparameter settings, e.g. the learning rate. Here, we will try a simple random search to find good values of the latent factor dimension $k$, the batch size, learning rate, and regularization.  \n",
    "\n",
    "### Tasks:\n",
    "\n",
    "Perform a hyperparameter search to find good values for the batch size, lambda, learning rate, and latent dimension. \n",
    "\n",
    "* For the batch size, evaluate all values in [1, 32, 512, -1] (-1 corresponds to full-sweep gradient descent).\n",
    "* For $\\lambda$, randomly sample three values in the interval [0, 1).\n",
    "* For the learning rate, evaluate all values in [1, 0.1, 0.01].\n",
    "* For the latent dimension, uniformly sample three values in the interval [5,30].\n",
    "\n",
    "Perform an exhaustive search among all combinations of these values;\n",
    "\n",
    "**Hint**: This may take a while to compute. **You don't have to wait for all the models to train** -- simply use \"dummy\" code instead of actual model training (or let it train, e.g., for only one iteration) if you don't want to wait. Note that the signature of this dummy code has to match the function 'latent_factor_gradient_descent' so that we could simply plug in the actual function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Students' comment:\n",
    "\n",
    "**Note**: \n",
    "In order to get converging optimization the evaluated learning rates are adjusted to [1e-2, 1e-3, 1e-4]. <br> Furthermore, the range range of $\\lambda$ is changed to [0, 0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_search(M_train, val_idx, val_values):\n",
    "    \"\"\"\n",
    "    Hyperparameter search using random search.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    M_train     : sp.spmatrix, shape [N, D]\n",
    "                  Input sparse matrix where the user means have not\n",
    "                  been subtracted yet. \n",
    "                  \n",
    "    val_idx     : tuple, shape [2, n_validation]\n",
    "                  The indices used for validation, where n_validation\n",
    "                  is the size of the validation set.\n",
    "                  \n",
    "    val_values  : np.array, shape [n_validation, ]\n",
    "                  Validation set values, where n_validation is the\n",
    "                  size of the validation set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_conf   : tuple, (batch_size, lambda, learning_rate, latent_dimension)\n",
    "                  The best-performing hyperparameters.\n",
    "    \n",
    "    best_Q      : np.array, shape [N, k]\n",
    "                  Best value for Q (based on validation loss) observed during all configurations\n",
    "                      \n",
    "    best_P      : np.array, shape [k, D]\n",
    "                  Best value for P (based on validation loss) observed during all configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE ### ===> DONE\n",
    "    \n",
    "    # Store away the nonzero indices of M before substracting the row means.\n",
    "    nonzero_indices =  M_train.nonzero()\n",
    "    # Remove user means.\n",
    "    M_shifted, _ = shift_user_mean(M_train)\n",
    "    \n",
    "    #Define the sets of hyperparameters\n",
    "    batch_sizes = [1, 32, 512, -1]\n",
    "    reg_lambdas = 0.1 * np.random.sample((3,))\n",
    "    learning_rates = [1e-2, 1e-3, 1e-4]\n",
    "    latent_dimensions = np.random.randint(5, 31, (3,))\n",
    "    \n",
    "    max_steps = 2\n",
    "    \n",
    "    #iterate over all combinations of hyperparameters\n",
    "    for batch_size in batch_sizes:\n",
    "        for reg_lambda in reg_lambdas:\n",
    "            for learning_rate in learning_rates:\n",
    "                for k in latent_dimensions:\n",
    "                    \n",
    "                    conf = (batch_size, reg_lambda, learning_rate, k)\n",
    "                    print(\"Training with configuration {}\".format(conf))\n",
    "                    \n",
    "                    #perform latent factor gradient descent for all combinations of hyperparameters\n",
    "                    Q, P, val_l_g_opt, _, _ = latent_factor_gradient_descent(M_shifted, nonzero_indices, \n",
    "                                                                             k, val_idx=val_idx, \n",
    "                                                                             val_values=val_values_shifted, \n",
    "                                                                             reg_lambda = reg_lambda, learning_rate = learning_rate, \n",
    "                                                                             batch_size = batch_size, max_steps = max_steps, \n",
    "                                                                             init='svd', log_every=500, \n",
    "                                                                             eval_every=50)\n",
    "                    \n",
    "                    \n",
    "                    #Get the best validation loss for the hyperparameters\n",
    "                    min_val_l = min(val_l_g_opt)\n",
    "                    print(\"Done. Best validation loss {}\".format(min_val_l))\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        #If the current hyperparameters lead to a better validation loss than all previous combinations\n",
    "                        #before --> update the best configuration\n",
    "                        if min_val_l < best_val_l:\n",
    "                            best_val_l = min_val_l\n",
    "                            best_conf = conf\n",
    "                            best_Q = Q\n",
    "                            best_P = P\n",
    "                            print(\"New best configuration: {}\".format(best_conf))\n",
    "                            \n",
    "                    #If first iteration: best_val_l is not defined yet and a NameError is raised\n",
    "                    #Initialize best configuration as first configuration\n",
    "                    except NameError:\n",
    "                        best_val_l = min_val_l\n",
    "                        best_conf = conf\n",
    "                        best_Q = Q\n",
    "                        best_P = P\n",
    "                        print(\"New best configuration: {}\".format(best_conf))\n",
    "                        \n",
    "                    print('\\n')\n",
    "  \n",
    "    print(\"Best configuration is {}\".format(best_conf))\n",
    "    return best_conf, best_Q, best_P\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_configuration, best_Q_g, best_P_g = parameter_search(M_train, val_idx, val_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the best hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ### ===> DONE\n",
    "\n",
    "print(\"Best batch size: {}\".format(best_configuration[0]))\n",
    "print(\"Best lambda: {}\".format(best_configuration[1]))\n",
    "print(\"Best learning rate: {}\".format(best_configuration[2]))\n",
    "print(\"Best latent dimension: {}\".format(best_configuration[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison of gradient descent and alternating optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the latent factor model with both alternating optimization and gradient descent, we now compare their results on the training, validation, and test set.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* Compare the root mean square errors (RMSE) for the training, validation, and test sets different settings of $k$ for both alternating optimization and gradient descent. What do you observe?\n",
    "* Compare the test RMSE for the alternating optimization model and the gradient descent model. Which performs better?\n",
    "* Plot the predicted ratings\n",
    "\n",
    "**Hint**: The output values and plots below are the ones we got when testing this sheet. Yours may be different, but if your validation or test RMSE values are larger than 1.5 or 2, it is likely that you have a bug in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ### ==> DONE\n",
    "\n",
    "def get_shifted_predictions(indices, Q, P):\n",
    "    shifted_values = np.sum(Q[indices[0]] * P.T[indices[1]], axis = 1)\n",
    "    return shifted_values\n",
    "\n",
    "def get_root_square_mean_error(true_values, prediction):\n",
    "    return np.mean(np.square(true_values - prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ### ==> DONE\n",
    "\n",
    "train_values_a = M_shifted[nonzero_indices].A1\n",
    "train_predicted_a = get_shifted_predictions(nonzero_indices, Q_a, P_a)\n",
    "train_error_a = get_root_square_mean_error(train_values_a, train_predicted_a)\n",
    "val_predicted_a = get_shifted_predictions(val_idx, Q_a, P_a)\n",
    "val_error_a = get_root_square_mean_error(val_values_shifted, val_predicted_a)\n",
    "test_predicted_a = get_shifted_predictions(test_idx, Q_a, P_a)\n",
    "test_error_a = get_root_square_mean_error(test_values_shifted, test_predicted_a)\n",
    "\n",
    "print(\"Training RMSE of alternating optimization model: {}\".format(train_error_a))\n",
    "print(\"Validation RMSE of alternating optimization model: {}\".format(val_error_a))\n",
    "print(\"Test RMSE of alternating optimization model: {}\".format(test_error_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ### ==> DONE\n",
    "\n",
    "train_values_g = M_shifted[nonzero_indices].A1\n",
    "train_predicted_g = get_shifted_predictions(nonzero_indices, best_Q_g, best_P_g)\n",
    "train_error_g = get_root_square_mean_error(train_values_g, train_predicted_g)\n",
    "val_predicted_g = get_shifted_predictions(val_idx, best_Q_g, best_P_g)\n",
    "val_error_g = get_root_square_mean_error(val_values_shifted, val_predicted_g)\n",
    "test_predicted_g = get_shifted_predictions(test_idx, best_Q_g, best_P_g)\n",
    "test_error_g = get_root_square_mean_error(test_values_shifted, test_predicted_g)\n",
    "\n",
    "print(\"Training RMSE of best gradient descent model: {}\".format(train_error_g))\n",
    "print(\"Validation RMSE of best gradient descent model: {}\".format(val_error_g))\n",
    "print(\"Test RMSE of best gradient descent model: {}\".format(test_error_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots: Prediction vs. ground truth ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.scatter(train_values_a, train_predicted_a, 'MarkerFaceAlpha', 0.2)\n",
    "plt.xlabel('Ground truth training rating')\n",
    "plt.ylabel('Predicted rating')\n",
    "plt.title('Training ratings vs. predictions by alternating optimization model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "plt.scatter(train_values_g, train_predicted_g, 'MarkerFaceAlpha', 0.2)\n",
    "plt.xlabel('Ground truth training rating')\n",
    "plt.ylabel('Predicted rating')\n",
    "plt.title('Training ratings vs. predictions by gradient descent model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.scatter(val_values_a, val_predicted_a, 'MarkerFaceAlpha', 0.2)\n",
    "plt.xlabel('Ground truth training rating')\n",
    "plt.ylabel('Predicted rating')\n",
    "plt.title('Valdidation ratings vs. predictions by alternating optimization model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.scatter(train_values_g, train_predicted_g, 'MarkerFaceAlpha', 0.2)\n",
    "plt.xlabel('Ground truth training rating')\n",
    "plt.ylabel('Predicted rating')\n",
    "plt.title('Validation ratings vs. predictions by gradient descent model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.scatter(test_values_a, test_predicted_a, 'MarkerFaceAlpha', 0.2)\n",
    "plt.xlabel('Ground truth training rating')\n",
    "plt.ylabel('Predicted rating')\n",
    "plt.title('Test ratings vs. predictions by alternating optimization model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTTING CODE HERE ### ==> DONE\n",
    "\n",
    "plt.scatter(test_values_g, test_predicted_g, 'MarkerFaceAlpha', 0.2)\n",
    "plt.xlabel('Ground truth training rating')\n",
    "plt.ylabel('Predicted rating')\n",
    "plt.title('Test ratings vs. predictions by gradient descent model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
